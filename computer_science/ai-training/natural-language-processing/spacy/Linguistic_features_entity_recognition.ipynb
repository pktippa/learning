{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition under Linguistic Features\n",
    "\n",
    "Link [here](https://spacy.io/usage/linguistic-features#named-entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default model identifies a variety of named and numeric entities, including companies, locations, \n",
    "organizations and products.\n",
    "\n",
    "You can add arbitrary classes to the entity recognition system, and update the model with new examples.\n",
    "\n",
    "Because models are statistical and strongly depend on the examples they were trained on, \n",
    "this doesn't always work perfectly and might need some tuning later, depending on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading language model\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text -  Netflix  | label -  PERSON\n",
      "text -  VP  | label -  ORG\n"
     ]
    }
   ],
   "source": [
    "# Creating the document from the sentence\n",
    "doc = nlp(u'Netflix is hiring a new VP of global policy')\n",
    "# TODO: From documentation - https://spacy.io/usage/linguistic-features#setting-entities\n",
    "# it says it didnt recognize entities but the model actually recognized some entities\n",
    "\n",
    "# TODO: If we load large model - \"en_core_web_lg\", does it recognize correctly ?\n",
    "for e in doc.ents:\n",
    "    print('text - ', e.text, ' | label - ', e.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Netflix\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is hiring a new \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    VP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " of global policy</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "# Observations\n",
    "# 1. Netflix is identified as PERSON entity, rather it is an ORG / company\n",
    "# 2. VP is identified as ORG, rather it should a person\n",
    "# Now lets override and assert the same below\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Entities -  [('Netflix', 0, 7, 'ORG'), ('VP', 24, 26, 'PERSON')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Netflix\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is hiring a new \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    VP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " of global policy</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing Span from spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "doc = nlp(u'Netflix is hiring a new VP of global policy')\n",
    "\n",
    "# get hash values of entity labels\n",
    "ORG = doc.vocab.strings[u'ORG'] \n",
    "PERSON = doc.vocab.strings[u'PERSON']\n",
    "\n",
    "# creating Span(s) for the new entities\n",
    "# Note: Span with the start and end index of the token, not the start and end index of the entity in the document.\n",
    "netflix_ent = Span(doc, 0, 1, label=ORG) # Netflix is first token so indexes is 0:1\n",
    "vp_ent = Span(doc, 5, 6, label=PERSON) # VP is 6th token so indexes is 5:6\n",
    "\n",
    "# Overriding original entities\n",
    "doc.ents = [netflix_ent, vp_ent]\n",
    "\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('Modified Entities - ', ents)\n",
    "assert ents == [(u'Netflix', 0, 7, u'ORG'), (u'VP', 24, 26, u'PERSON')] # assetion should be successful\n",
    "\n",
    "# Now lets visualize the new entites\n",
    "# You can see that now \"Netflix\" entity is changed to \"ORG\" and \"VP\" is changed to \"PERSON\"\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London is a big city in the United Kingdom."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting entity annotations from array\n",
    "import numpy\n",
    "from spacy.attrs import ENT_IOB, ENT_TYPE\n",
    "\n",
    "# Making a new document, which will not do any entity tagging\n",
    "doc = nlp.make_doc(u'London is a big city in the United Kingdom.')\n",
    "\n",
    "# Entities are empty\n",
    "assert list(doc.ents) == []\n",
    "\n",
    "# Creating headers\n",
    "header = [ENT_IOB, ENT_TYPE]\n",
    "\n",
    "# Initializing array with numpy zeros\n",
    "attr_array = numpy.zeros((len(doc), len(header)))\n",
    "\n",
    "# TODO: Need more understanding\n",
    "attr_array[0, 0] = 2 # B\n",
    "attr_array[0, 1] = doc.vocab.strings[u'GPE']\n",
    "doc.from_array(header, attr_array)\n",
    "# TODO: Assertion fails\n",
    "#assert list(doc.ents)[0].text == u'London'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built in Entity Types [here](https://spacy.io/usage/linguistic-features#entity-types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding special case Tokenization rules\n",
    "# https://spacy.io/usage/linguistic-features#special-cases\n",
    "\n",
    "# Importing necessary symbols from spacy\n",
    "from spacy.symbols import ORTH, LEMMA, POS, TAG\n",
    "\n",
    "# New sentence wanted to tokenize\n",
    "doc = nlp(u'gimme that')\n",
    "assert [w.text for w in doc] == [u'gimme', u'that'] # current tokenization has only 2 tokens\n",
    "\n",
    "# add special case rule\n",
    "special_case = [{ORTH: u'gim', LEMMA: u'give', POS: u'VERB'}, {ORTH: u'me'}]\n",
    "\n",
    "# Adding the special case to tokenizer, which will be affective from next sentence parsing\n",
    "nlp.tokenizer.add_special_case(u'gimme', special_case)\n",
    "\n",
    "assert [w.text for w in nlp(u'gimme that')] == [u'gim', u'me', u'that'] # After customization got 3 tokens\n",
    "# Pronoun lemma is returned as -PRON-!\n",
    "assert [w.lemma_ for w in nlp(u'gimme that')] == [u'give', u'-PRON-', u'that']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The special case doesn't have to match an entire whitespace-delimited substring. \n",
    "# The tokenizer will incrementally split off punctuation, and keep looking up the remaining substring\n",
    "\n",
    "# gimme! when split it returns 3 values gim, me, ! and lemmas are give, -PRON-, !\n",
    "assert 'gimme' not in [w.text for w in nlp(u'gimme!')] # gimme should not be there in token texts\n",
    "assert [w.lemma_ for w in nlp(u'gimme!')] == [u'give', u'-PRON-', u'!'] # lemmas should be give, -PRON-, !\n",
    "\n",
    "# Tokenizing works even with the string part of the periods and punctuations\n",
    "assert 'gimme' not in [w.text for w in nlp(u'(\"...gimme...?\")')]\n",
    "# Asserting lemmas for '...gimme...?'\n",
    "assert [w.lemma_ for w in nlp(u'...gimme...?')] == [u'...', u'give', u'-PRON-', u'...', u'?'] \n",
    "\n",
    "# Adding another case for matching the whole \"...gimme...?\" to a single token\n",
    "special_case = [{ORTH: u'...gimme...?', LEMMA: u'give', TAG: u'VB'}]\n",
    "nlp.tokenizer.add_special_case(u'...gimme...?', special_case)\n",
    "\n",
    "# the length of tokens should be one\n",
    "assert len(nlp(u'...gimme...?')) == 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
