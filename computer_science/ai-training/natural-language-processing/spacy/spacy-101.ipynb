{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the language model\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the document object after parsing/processing the text\n",
    "# u - represents the string is in unicode format\n",
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "# Tokenization details, see more https://spacy.io/usage/spacy-101#annotations-token\n",
    "# Observations \n",
    "# here are U.K. is not separated out as two different words, even if there is a punctuation('.')\n",
    "# $1 is separated out as two words even if there is no space between them\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple apple PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. u.k. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "# Part-of-Speech tags and dependencies, see more https://spacy.io/usage/spacy-101#annotations-pos-deps\n",
    "# After tokenization spacy does the POS tags and dependencies\n",
    "# Linguistic annotations are available as Token attributes\n",
    "\n",
    "# Text: The original word text.\n",
    "# Lemma: The base form of the word.\n",
    "# POS: The simple part-of-speech tag.\n",
    "# Tag: The detailed part-of-speech tag.\n",
    "# Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "# Shape: The word shape â€“ capitalisation, punctuation, digits.\n",
    "# is alpha: Is the token an alpha character?\n",
    "# is stop: Is the token part of a stop list, i.e. the most common words of the language?\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing displacy from spacy\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS - PROPN -  proper noun\n",
      "tag - VBZ -  verb, 3rd person singular present\n",
      "dep label - dobj -  direct object\n"
     ]
    }
   ],
   "source": [
    "# Understanding pos, tags and dep labels - using spacy.explain()\n",
    "print('POS - PROPN - ', spacy.explain('PROPN'))\n",
    "print('tag - VBZ - ', spacy.explain('VBZ'))\n",
    "print('dep label - dobj - ', spacy.explain('dobj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "# Named Entities\n",
    "\n",
    "# Text: The original entity text.\n",
    "# Start: Index of start of entity in the Doc.\n",
    "# End: Index of end of entity in the Doc.\n",
    "# Label: Entity label, i.e. type.\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog  smililarity to  dog  -  1.0\n",
      "dog  smililarity to  cat  -  0.53906965\n",
      "dog  smililarity to  banana  -  0.28761008\n",
      "cat  smililarity to  dog  -  0.53906965\n",
      "cat  smililarity to  cat  -  1.0\n",
      "cat  smililarity to  banana  -  0.48752153\n",
      "banana  smililarity to  dog  -  0.28761008\n",
      "banana  smililarity to  cat  -  0.48752153\n",
      "banana  smililarity to  banana  -  1.0\n"
     ]
    }
   ],
   "source": [
    "# Word Vectors and Similarity\n",
    "# spaCy is able to compare two objects, and make a prediction of \"how similar they are\".\n",
    "\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "# TODO: Similarity from dog to cat is bad, we can check the by loading large - en_core_web_lg - model.# \n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1, ' smililarity to ', token2 , ' - ', token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking word vectors availability\n",
    "tokens = nlp(u'dog cat banana sasquatch')\n",
    "\n",
    "# TODO: Load the large model and verify the same\n",
    "\n",
    "# Text: The original token text.\n",
    "# has vector: Does the token have a vector representation?\n",
    "# Vector norm: The L2 norm of the token's vector (the square root of the sum of the values squared)\n",
    "# is OOV: Is the word out-of-vocabulary?\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4690420944186131903 X I I True False True en\n",
      "love 3702023516439754181 xxxx l ove True False False en\n",
      "coffee 3197928453018144401 xxxx c fee True False False en\n"
     ]
    }
   ],
   "source": [
    "# Vocab, hashes and lexemes, more here https://spacy.io/usage/spacy-101#vocab\n",
    "doc = nlp(u'I love coffee')\n",
    "\n",
    "# Text: The original text of the lexeme.\n",
    "# Orth: The hash value of the lexeme.\n",
    "# Shape: The abstract word shape of the lexeme.\n",
    "# Prefix: By default, the first letter of the word string.\n",
    "# Suffix: By default, the last three letters of the word string.\n",
    "# is alpha: Does the lexeme consist of alphabetic characters?\n",
    "# is digit: Does the lexeme consist of digits?\n",
    "\n",
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\n",
    "          lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialization here https://spacy.io/usage/spacy-101#serialization\n",
    "\n",
    "# TODO - Add More"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
