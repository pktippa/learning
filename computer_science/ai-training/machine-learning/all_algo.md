# All Algorithms

## Linear Regression

The cost function for linear regression is always a bowl shaped or convex shaped function.

So it always has a global optimum but not a local optimum.

## Linear Regression with Multiple variables

Linear regression with multiple variables is also known as "multivariate linear regression".

## Logistic Regression

It is algorithm for Binary Classification.

h_theta(x) = g( theta_transpose * X )

where

g(z) = 1 / (1 + e^-z) this is called sigmoid function or logistic function

## Support Vector Machine (SVM)

A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side.

## Other Optimizing algorithms for minimizing Cost apart from Gradient Descent

* Conjugate gradient
* BFGS
* L-BFGS

Uses line search algorithm