# Machine Learning basics

## Supervised learning recipe

1. Collect training data
2. Train Classifier
3. Make Predictions

Just like in programming, testing is a very important part of ML.

In machine learning, having more data is almost always more important that having better algorithms.

In the process of training / validating the model is then shown the unlabelled text and will make a prediction. Because we know the correct answer, we can give the model feedback on its prediction in the form of an `error gradient` of the `loss function` that calculates the difference between the training example and the expected output. The greater the difference, the more significant the gradient and the updates to our model.

Data value types:

1. Categorical values

- [Natural Lanugage Processing](nlp/README.md)

## Neural Networks

- [Neural Networks](neural_networks/README.md)

## Statistics

- [Statistics](statistics/README.md)

## Matplotlib

- [MatplotLib](matplotlib/README.md)

## Cost / Error

- [Cost or Error](cost_or_error/README.md)

## Loss functions

- [Loss Functions](loss-functions/README.md)

## Problem solving Steps

- [Solving Steps](steps.md)

## Others

- Softmax function which converts classified labels scores into probabilities. Softmax Function S(yi) = exp(yi) / Sigsum(exp(yi))
